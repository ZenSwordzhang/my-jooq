input {
    http {
        port => 8088
        codec => "json"
        add_field => {
            source => "http"
            from => "app"
        }
        # 自定义用户：拥有manage_index_templates、monitor、manage_ilm等权限
        user => "logstash_writer_user"
        password => "123456"
    }
    http {
        port => 9600
        user => "logstash_writer_user"
        password => "123456"
        add_field => {
            source => "log"
            from => "spring"
        }
    }
    beats {
        port => 5044
        add_field => {
            source => "beats"
        }
        ssl => true
        # This key need to be in the PKCS8 format
        ssl_key => "${CERTS_DIR_LOGSTASH}/instance/instance.pem"
        ssl_certificate => "${CERTS_DIR_LOGSTASH}/instance/instance.crt"
        ssl_certificate_authorities => "${CERTS_DIR_LOGSTASH}/ca/ca.crt"
        ssl_verify_mode => "force_peer"
    }
    file {
        add_field => {
            source => "file"
            from => "spring"
        }
        path => ["/usr/share/logstash/logs/test.log"]
        sincedb_path => "NUL"
        start_position => "beginning"
    }
}
filter {
    if [source] == "log" {
        grok {
            # Do multiline matching with (?m) as the above mutliline filter may add newlines to the log messages.
            match => [ "message", "(?m)^%{TIMESTAMP_ISO8601:timestamp}%{SPACE}%{LOGLEVEL:logLevel}%{SPACE}%{NUMBER:pid}%{SPACE}---%{SPACE}\[%{SPACE}%{DATA:thread}\]%{SPACE}%{NOTSPACE:class}%{SPACE}:%{SPACE}%{GREEDYDATA:message}" ]
            overwrite => [ "message" ]
        }
    }
    if ![env] {
        ruby {
            code => "event.set('env', 'dev')"
        }
    }
}
output {
    elasticsearch {
        hosts => ["http://es01:9200"]
        index => "%{[source]}-%{[from]}-%{+YYYYMMdd}"
        # 自定义用户：拥有manage_index_templates、monitor、manage_ilm等权限
        user => "logstash_writer_user"
        password => "123456"
        manage_template => false
    }
}
